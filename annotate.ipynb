{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Annotation pipeline: FinBERT sentiment + regex ticker extraction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import re\n","import pandas as pd\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","\n","# load FinBERT\n","tokenizer = AutoTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n","model = AutoModelForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone')\n","\n","# sample tweets\n","tweets = pd.read_csv('sample_tweets.csv', parse_dates=['created_at'])\n","\n","# regex for tickers (e.g. $AAPL)\n","ticker_pattern = re.compile(r\"\\$[A-Z]{1,5}\\b\")\n","\n","def annotate_row(row):\n","    text = row['text']\n","    # sentiment\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n","    outputs = model(**inputs)\n","    scores = torch.nn.functional.softmax(outputs.logits, dim=1)[0]\n","    row['sent_bear'] = scores[0].item()\n","    row['sent_neut'] = scores[1].item()\n","    row['sent_bull'] = scores[2].item()\n","    # tickers\n","    row['tickers'] = ticker_pattern.findall(text)\n","    return row\n","\n","annotated = tweets.apply(annotate_row, axis=1)\n","annotated.to_csv('sample_tweets_annotated.csv', index=False)"]}],"metadata":{"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
